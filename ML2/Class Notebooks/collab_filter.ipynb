{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe531b6-168d-49e5-8808-1fb1470c9b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_year</th>\n",
       "      <th>artist_pop</th>\n",
       "      <th>track_pop</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>double take</td>\n",
       "      <td>Dhruv</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>171.743</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Last Kiss</td>\n",
       "      <td>Hikaru Utada</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>252.026</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>NIKI</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>79</td>\n",
       "      <td>72</td>\n",
       "      <td>232.800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet Heat Lightning</td>\n",
       "      <td>Gregory Alan Isakov</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>286.120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brothers In Arms - Remastered 1996</td>\n",
       "      <td>Dire Straits</td>\n",
       "      <td>5</td>\n",
       "      <td>1985</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>420.240</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           song_title          artist_name  release_month  \\\n",
       "0                         double take                Dhruv              1   \n",
       "1                       One Last Kiss         Hikaru Utada              3   \n",
       "2                              Autumn                 NIKI              8   \n",
       "3                Sweet Heat Lightning  Gregory Alan Isakov              8   \n",
       "4  Brothers In Arms - Remastered 1996         Dire Straits              5   \n",
       "\n",
       "   release_year  artist_pop  track_pop  duration_s  explicit  \n",
       "0          2022          66         78     171.743     False  \n",
       "1          2021          73         63     252.026     False  \n",
       "2          2022          79         72     232.800     False  \n",
       "3          2023          73         78     286.120     False  \n",
       "4          1985          81         74     420.240     False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "spot = pd.read_csv(\"ds4420_spotify.csv\")\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945740b9-2789-4fc9-bf44-6c346b09ec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_year</th>\n",
       "      <th>artist_pop</th>\n",
       "      <th>track_pop</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Finally Over It</td>\n",
       "      <td>Summer Walker</td>\n",
       "      <td>11</td>\n",
       "      <td>2025</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>143.746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Like a Tattoo</td>\n",
       "      <td>Sade</td>\n",
       "      <td>10</td>\n",
       "      <td>1992</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>218.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Call On Me</td>\n",
       "      <td>Daniel Caesar</td>\n",
       "      <td>10</td>\n",
       "      <td>2025</td>\n",
       "      <td>88</td>\n",
       "      <td>70</td>\n",
       "      <td>169.004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Center Mass</td>\n",
       "      <td>Twenty One Pilots</td>\n",
       "      <td>9</td>\n",
       "      <td>2025</td>\n",
       "      <td>85</td>\n",
       "      <td>68</td>\n",
       "      <td>228.173</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>222.973</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          song_title        artist_name  release_month  release_year  \\\n",
       "178  Finally Over It      Summer Walker             11          2025   \n",
       "179    Like a Tattoo               Sade             10          1992   \n",
       "180       Call On Me      Daniel Caesar             10          2025   \n",
       "181      Center Mass  Twenty One Pilots              9          2025   \n",
       "182   Mr. Brightside        The Killers              6          2004   \n",
       "\n",
       "     artist_pop  track_pop  duration_s  explicit  \n",
       "178          80         70     143.746     False  \n",
       "179          81         82     218.000     False  \n",
       "180          88         70     169.004     False  \n",
       "181          85         68     228.173     False  \n",
       "182          80         91     222.973     False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29c52d7-b0a2-4293-8eff-caea7237f571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5017626 , -0.72739308],\n",
       "       [-0.08110953,  0.04624362],\n",
       "       [ 0.27945024, -0.13902523],\n",
       "       [-0.08110953,  0.37478603],\n",
       "       [ 0.39963683,  1.667216  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "num_spot = spot.iloc[:, [4, 6]].to_numpy()\n",
    "scaler = StandardScaler()\n",
    "scale_spot = scaler.fit_transform(num_spot)\n",
    "scale_spot[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b1e474-0acc-4415-8671-967fdacd6977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33954354],\n",
       "       [-0.23372184]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example x, y, z\n",
    "x = scale_spot[0].reshape(-1, 1) # double take\n",
    "y = scale_spot[1].reshape(-1, 1) # One Last Kiss\n",
    "z = scale_spot[182].reshape(-1, 1) # Mr. Brightside\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9709ba-d7b1-4084-816f-4ef6f8b66b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1_x_z': np.float64(1.3349773802070826),\n",
       " 'L1_y_z': np.float64(0.7006185308437332),\n",
       " 'L2_x_z': np.float64(0.9754523622981865),\n",
       " 'L2_y_z': np.float64(0.5053015573481016),\n",
       " 'Linf_x_z': np.float64(0.8413061349714686),\n",
       " 'Linf_y_z': np.float64(0.4206530674857343)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distances\n",
    "# Notice R and Python have slightly different norm functions due to rounding\n",
    "distances = {\n",
    "    \"L1_x_z\": np.linalg.norm(z - x, ord=1),\n",
    "    \"L1_y_z\": np.linalg.norm(z - y, ord=1),\n",
    "    \"L2_x_z\": np.linalg.norm(z - x, ord=2),\n",
    "    \"L2_y_z\": np.linalg.norm(z - y, ord=2),\n",
    "    \"Linf_x_z\": np.linalg.norm(z - x, ord=np.inf),\n",
    "    \"Linf_y_z\": np.linalg.norm(z - y, ord=np.inf),\n",
    "}\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3278e7c-568e-42ca-99f8-720bd9fce6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_C(z,x): -0.0009954513839126454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -9.95451384e-04, -9.96416306e-01],\n",
       "       [-9.95451384e-04,  1.00000000e+00,  8.55763838e-02],\n",
       "       [-9.96416306e-01,  8.55763838e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "# individual pair (z vs. x)\n",
    "print(f'S_C(z,x): {cosine_similarity(np.vstack([z.T, x.T]))[0, 1]}')\n",
    "\n",
    "# all pairs\n",
    "cosine_similarity(np.vstack([z.T, x.T, y.T]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fa03f9-910e-491a-88f0-00d4e2ec3b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.54554473,  0.54554473,  0.26190476,  0.69293487],\n",
       "       [-0.54554473,  1.        , -1.        , -0.10910895, -0.8660254 ],\n",
       "       [ 0.54554473, -1.        ,  1.        ,  0.10910895,  0.8660254 ],\n",
       "       [ 0.26190476, -0.10910895,  0.10910895,  1.        , -0.25197632],\n",
       "       [ 0.69293487, -0.8660254 ,  0.8660254 , -0.25197632,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collaborative Filtering Example\n",
    "drg = np.array([[-5 / 3, 0, 4 / 3, 1 / 3]])\n",
    "st1 = np.array([[1, -1, 0, 0]])\n",
    "st2 = np.array([[-2, 2, 0, 0]])\n",
    "st3 = np.array([[0, 1 / 3, 4 / 3, -5 / 3]])\n",
    "st4 = np.array([[-2 / 3, 1 / 3, 0, 1 / 3]])\n",
    "\n",
    "similarity_matrix = cosine_similarity(np.vstack((drg, st1, st2, st3, st4)))\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a5220b-3b4e-4ee2-8e1b-6cc6a16e587e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.559504469211125)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rating = (\n",
    "    similarity_matrix[0, 2] * 4 + similarity_matrix[0, 4] * 5\n",
    ") / (similarity_matrix[0, 2] + similarity_matrix[0, 4])\n",
    "predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4363cb-7540-4d33-bd52-a07afd17e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4\n",
      "0       NaN  0.510113  0.828255  1.000000  0.900066\n",
      "1  0.000000       NaN  0.000000  0.278016  0.000000\n",
      "2  0.880991  0.000000       NaN  0.702663  1.000000\n",
      "3  0.651968  1.000000  0.594370       NaN  0.354521\n",
      "4  1.000000  0.150383  1.000000  0.000000       NaN\n"
     ]
    }
   ],
   "source": [
    "# MinMax Scaling of each Score\n",
    "# This step is necessary!\n",
    "# Set diagonal elements to NaN\n",
    "np.fill_diagonal(similarity_matrix, np.nan)\n",
    "\n",
    "sim_scores_scaled = pd.DataFrame(similarity_matrix).apply(\n",
    "    lambda x: (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x)), axis=0\n",
    ")\n",
    "\n",
    "# NOTE: We look down the columnns! (the matrix isn't symmetric...)\n",
    "print(sim_scores_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07aecaf3-8358-4045-aea7-013f44a71566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.013245033112583"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(.510*4 + 1*1)/(.510 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c7a856-26e3-4da0-9280-1ff13a9a3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0904170507256365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.468365363118093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And, Dr. Gerber's Song 2 (for completion's sake) using all other users\n",
    "print(sum(sim_scores_scaled.iloc[1:,0] * [3, 5, 3, 4]) / sum(sim_scores_scaled.iloc[1:,0]))\n",
    "\n",
    "# Or, just the top 2\n",
    "sum(sim_scores_scaled.iloc[[2,4],0] * [5, 4]) / sum(sim_scores_scaled.iloc[[2,4],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae61bc5-f19f-4eea-aa0d-61bb67712869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5017626 , -0.72739308,  0.        ],\n",
       "       [-0.08110953,  0.04624362,  0.        ],\n",
       "       [ 0.27945024, -0.13902523,  0.        ],\n",
       "       [-0.08110953,  0.37478603,  0.        ],\n",
       "       [ 0.39963683,  1.667216  ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# content-based filtering\n",
    "# add the \"explicit\" column to the scaled data\n",
    "explicit = spot['explicit'].astype(int).to_numpy().reshape(-1, 1)\n",
    "full_spot = np.hstack((scale_spot, explicit))\n",
    "full_spot[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f5a512-9383-4de8-afd1-eda561e3d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>sim_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Like a Tattoo</td>\n",
       "      <td>Sade</td>\n",
       "      <td>0.999939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>WHERE IS MY HUSBAND!</td>\n",
       "      <td>RAYE</td>\n",
       "      <td>0.998915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>We Don't Talk Anymore (feat. Selena Gomez)</td>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>0.994790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>How Long</td>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>0.994257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           song        artist  sim_scores\n",
       "182                              Mr. Brightside   The Killers    1.000000\n",
       "179                               Like a Tattoo          Sade    0.999939\n",
       "175                        WHERE IS MY HUSBAND!          RAYE    0.998915\n",
       "128  We Don't Talk Anymore (feat. Selena Gomez)  Charlie Puth    0.994790\n",
       "57                                     How Long  Charlie Puth    0.994257"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Song #182 corresponds to \"Mr. Brightside\"\n",
    "drg = full_spot[182].reshape(1, -1)\n",
    "cosine_sim_to_drg = []\n",
    "\n",
    "# calculate cosine similarity for each song relative to \"Mr. Brightside\"\n",
    "for i in range(full_spot.shape[0]):\n",
    "    temp_cosine = cosine_similarity(drg, full_spot[i].reshape(1, -1))[0, 0]\n",
    "    cosine_sim_to_drg.append(temp_cosine)\n",
    "\n",
    "similarity_df = pd.DataFrame({\n",
    "    'song': spot['song_title'],\n",
    "    'artist': spot['artist_name'],\n",
    "    'sim_scores': cosine_sim_to_drg\n",
    "})\n",
    "\n",
    "# sort the DataFrame by similarity scores in descending order\n",
    "similarity_df = similarity_df.sort_values(by='sim_scores', ascending=False)\n",
    "\n",
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27771bc2-5bcd-4647-94a8-8a00c3776358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75,   nan,  1.  ,  0.75],\n",
       "       [ 2.25, -0.75,   nan,  0.75],\n",
       "       [-1.75,  1.25, -1.  ,   nan],\n",
       "       [  nan, -0.75,  0.  , -2.25],\n",
       "       [ 0.25,  0.25,   nan,  0.75]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item-Item Example\n",
    "item_mat = np.array([\n",
    "    [2, np.nan, 5, 4],\n",
    "    [5, 3, np.nan, 4],\n",
    "    [1, 5, 3, np.nan],\n",
    "    [np.nan, 3, 4, 1],\n",
    "    [3, 4, np.nan, 4]\n",
    "])\n",
    "item_mat_scaled = item_mat - np.nanmean(item_mat, axis=0)\n",
    "item_mat_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a33f0a-7c92-4af9-9aa3-b8b3d14f11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-0.9008659350499821),\n",
       " np.float64(0.37139067635410367),\n",
       " np.float64(0.4236592728681617),\n",
       " np.float64(-0.8574929257125441),\n",
       " np.float64(0.4842001247062522),\n",
       " np.float64(0.31622776601683794)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute pairwise cosine similarities for items\n",
    "sim_scores = []\n",
    "for i in range(item_mat_scaled.shape[1] - 1):\n",
    "    for j in range(i + 1, item_mat_scaled.shape[1]):\n",
    "        SongA = item_mat_scaled[:, i]\n",
    "        SongB = item_mat_scaled[:, j]\n",
    "        shared = ~np.isnan(SongA) & ~np.isnan(SongB)\n",
    "        sim = cosine_similarity(SongA[shared].reshape(1, -1), SongB[shared].reshape(1, -1))[0, 0]\n",
    "        sim_scores.append(sim)\n",
    "\n",
    "sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06d07af-04cd-4371-9235-6eff8adf9c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03131476, 1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You should be able to create a similarity matrix as in user-user\n",
    "# But I will leave that to you on HW3\n",
    "# Min-Max Scale for Song 2\n",
    "Song2_scores = np.array([sim_scores[0], sim_scores[3], sim_scores[4]])\n",
    "scale_Song2 = (Song2_scores - np.min(Song2_scores)) / (np.max(Song2_scores) - np.min(Song2_scores))\n",
    "scale_Song2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418ffa6d-012b-4bdc-a870-c3b17e1435e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.030363919803004)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted Average to Predict\n",
    "sum(item_mat[0,~np.isnan(item_mat[0,])] * scale_Song2) / sum(scale_Song2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a6d446e-f46d-432a-8cee-4c7c7b99d727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75,  0.  ,  1.  ,  0.75],\n",
       "       [ 2.25, -0.75,  0.  ,  0.75],\n",
       "       [-1.75,  1.25, -1.  ,  0.  ],\n",
       "       [ 0.  , -0.75,  0.  , -2.25],\n",
       "       [ 0.25,  0.25,  0.  ,  0.75]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Intuition behind SVD for Recommender Systems\n",
    "# use the last matrix but centering by item and fill in the missing values\n",
    "# (Note: I'm centering on item because that's what I did last; user means are more common)\n",
    "\n",
    "R = np.array(item_mat_scaled, copy=True)\n",
    "R[np.isnan(R)] = 0\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a869f8-e2b5-4bcb-986d-2363807de137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.125  -1.125   0.3125 -1.6875  0.375 ]\n",
      " [-1.125   6.1875 -4.875  -1.125   0.9375]\n",
      " [ 0.3125 -4.875   5.625  -0.9375 -0.125 ]\n",
      " [-1.6875 -1.125  -0.9375  5.625  -1.875 ]\n",
      " [ 0.375   0.9375 -0.125  -1.875   0.6875]]\n"
     ]
    }
   ],
   "source": [
    "# review the user-user matrix\n",
    "user_user = R @ R.T\n",
    "print(user_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7b081b-82f2-4d93-9b93-87c1f8034343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4472136  -0.24609875 -0.79876071  0.29964111 -0.10785145]\n",
      " [ 0.4472136  -0.38452974  0.31910844  0.13023406  0.73030526]\n",
      " [ 0.4472136  -0.28800159  0.49139502  0.16489873 -0.6696226 ]\n",
      " [ 0.4472136   0.08070788 -0.10234188 -0.88440684 -0.0289295 ]\n",
      " [ 0.4472136   0.8379222   0.09059913  0.28963294  0.0760983 ]]\n"
     ]
    }
   ],
   "source": [
    "# what are the eigenvectors\n",
    "eigvals, eigvecs = np.linalg.eigh(user_user)  # eigh is for symmetric matrices\n",
    "# remember those\n",
    "print(eigvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12b7643-e05e-4984-b2d7-96dd3fda8a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10785145 -0.29964111  0.79876071 -0.24609875]\n",
      " [ 0.73030526 -0.13023406 -0.31910844 -0.38452974]\n",
      " [-0.6696226  -0.16489873 -0.49139502 -0.28800159]\n",
      " [-0.0289295   0.88440684  0.10234188  0.08070788]\n",
      " [ 0.0760983  -0.28963294 -0.09059913  0.8379222 ]]\n"
     ]
    }
   ],
   "source": [
    "# now, lets get the SVD\n",
    "# In numpy, svd returns U, singular values s, and Vt\n",
    "U, s, Vt = np.linalg.svd(R, full_matrices=False)\n",
    "\n",
    "# R_full$u # should look a little familiar...\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3647fbc3-b713-4eae-a6ae-68295f996fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88025608  0.055295   -0.32924191  0.33718166]\n",
      " [-0.40587305 -0.31567115 -0.32549887  0.79351703]\n",
      " [ 0.16964416 -0.05038645  0.88536313  0.42990022]\n",
      " [ 0.1778684  -0.94591511  0.04221824 -0.26800198]]\n"
     ]
    }
   ],
   "source": [
    "# Note: numpy gives Vt directly (V transpose)\n",
    "V = Vt.T\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cfd80ae-311d-42ed-b436-31d018e685b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.31146768 2.67417917 1.45720518 0.09747109]\n"
     ]
    }
   ],
   "source": [
    "# the S matrix is diagonal, python (like R) just gives those diagonal terms\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e1b669d-803a-480e-ae69-a42cb9e454b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.50000000e-01 -2.97314216e-16  1.00000000e+00  7.50000000e-01]\n",
      " [ 2.25000000e+00 -7.50000000e-01 -4.96171197e-17  7.50000000e-01]\n",
      " [-1.75000000e+00  1.25000000e+00 -1.00000000e+00  5.11975673e-16]\n",
      " [-1.51953224e-16 -7.50000000e-01  3.03102151e-16 -2.25000000e+00]\n",
      " [ 2.50000000e-01  2.50000000e-01 -1.87705388e-16  7.50000000e-01]]\n",
      "[[-0.75  0.    1.    0.75]\n",
      " [ 2.25 -0.75  0.    0.75]\n",
      " [-1.75  1.25 -1.    0.  ]\n",
      " [ 0.   -0.75  0.   -2.25]\n",
      " [ 0.25  0.25  0.    0.75]]\n"
     ]
    }
   ],
   "source": [
    "# Should be able to recover full matrix with\n",
    "R_recovered = U @ np.diag(s) @ Vt\n",
    "print(R_recovered)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "315d2ec7-e8bc-4a11-8770-b51b6bbee8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.74191185  0.0190345   1.01031224  0.7435713 ]\n",
      " [ 2.26263775 -0.72025856  0.01611289  0.73995514]\n",
      " [-1.74053469  1.27227547 -0.98793192 -0.00752331]\n",
      " [-0.0026525  -0.75624235 -0.00338189 -2.24789171]\n",
      " [ 0.2224613   0.18519094 -0.03511132  0.77188858]]\n"
     ]
    }
   ],
   "source": [
    "# But, the point is to pick only the most important latent features, k < 4\n",
    "# Note, the diagonal terms are sorted; the matrices are already sorted so that\n",
    "# the first k columns/rows are the most important! The fourth is much smaller than the third, so\n",
    "k = 3\n",
    "U_tilde = U[:, :k]\n",
    "S_tilde = np.diag(s[:k])\n",
    "VT_tilde = Vt[:k, :]\n",
    "\n",
    "# Our prediction matrix\n",
    "R_hat = U_tilde @ S_tilde @ VT_tilde\n",
    "print(R_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a61541b-74fa-4da8-a6fd-961b56820a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.00808815 3.7690345  5.01031224 3.9935713 ]\n",
      " [5.01263775 3.02974144 4.01611289 3.98995514]\n",
      " [1.00946531 5.02227547 3.01206808 3.24247669]\n",
      " [2.7473475  2.99375765 3.99661811 1.00210829]\n",
      " [2.9724613  3.93519094 3.96488868 4.02188858]]\n",
      "[[ 2. nan  5.  4.]\n",
      " [ 5.  3. nan  4.]\n",
      " [ 1.  5.  3. nan]\n",
      " [nan  3.  4.  1.]\n",
      " [ 3.  4. nan  4.]]\n"
     ]
    }
   ],
   "source": [
    "# Add the mean back to put it on the original scale\n",
    "# I'm using item means because I'm lazy and that's how I created item_mat_scaled\n",
    "# but, could have originally scaled with user means and done it that way (would give slightly different results)\n",
    "item_means = np.nanmean(item_mat, axis=0)  # mean per item/column ignoring NaNs\n",
    "R_hat_original_scale = R_hat + item_means\n",
    "print(R_hat_original_scale)\n",
    "\n",
    "# compare to original\n",
    "print(item_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
